{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a walkthrough on using `ConceptModel` methodology to effeciently create models useful for the applications that you have in mind. This notebook is a followup to the basic [Concept Model Demo notebook](./watsongraph - Concept Model Demo.ipynb), which introduces `ConceptModel` logic and operations and which you should read **first** before diving into this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "You may have heard of the principle of [six degrees of seperation](https://en.wikipedia.org/wiki/Six_degrees_of_separation), a fascinating theory from network analysis that states that any two people in the United States are at most six \"friend of friends\" distant from one another. This concept (the subject of a fantastical 1920s mail-order experiment) has since entered popular culture in forms such as [Bacon numbers](https://en.wikipedia.org/wiki/Bacon_number) and [Er≈ës numbers](https://en.wikipedia.org/wiki/Erd%C5%91s_number). Wikipedia has its own [six degrees principle](https://en.wikipedia.org/wiki/Wikipedia:Six_degrees_of_Wikipedia), a popular conception that all *sufficiently mainstream* Wikipedia articles are within six hops of one another, at most.\n",
    "\n",
    "How much entropy does Watson's cognitive graph have? To illustrate how far Watson's cognitive graph can wander let's take a few random 5-step walks. Try re-running this code block yourself. Where do you end up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watsongraph.conceptmodel import ConceptModel\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X Window System'"
      ]
     },
     "execution_count": 2,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "def jump(concept, level=0):\n",
    "    c = ConceptModel([concept])\n",
    "    c.explode(level=level)\n",
    "    l = len(c.concepts())\n",
    "    return c.concepts()[random.randrange(0, l)]\n",
    "\n",
    "jump(jump(jump(jump(jump('IBM')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Source code',\n",
       " 'Random-access memory',\n",
       " 'BSD licenses',\n",
       " 'Internet Explorer',\n",
       " 'MS-DOS']"
      ]
     },
     "execution_count": 3,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "[jump(jump(jump(jump(jump(i))))) for i in ['IBM'] * 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IBM System/3',\n",
       " 'IBM System/34',\n",
       " 'Processor book',\n",
       " 'Benjamin B. Redding',\n",
       " 'Inforex 1300 Systems']"
      ]
     },
     "execution_count": 4,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "[jump(jump(jump(jump(jump(i, level=3), level=3), level=3), level=3), level=3) for i in ['IBM'] * 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see, from the results above and from those of the queries that you yourself run, that the output of the cognitive graph is fairly tight: we can't even say definetively that it deteriorates significantly when we `explode()` at higher `level` parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "If you run the command above yourself you will also notice that though 15 queries doesn't sound like a lot it really piles on, especially once you start getting to higher level parameters: this query will take at least a minute to fully process. This is a key facet of modelling with `watsongraph`: the `Concept Insights` service, as brilliant as it is, is very time expensive. For this reason when constructing models using this service we actually want to *avoid* using it as much as possible: what that usually entails is backboning your graph locally, using other, faster data sources, and then only then expanding the connections amongst nodes to construct the graph.\n",
    "\n",
    "For our test usecase we will try to construct a \"corporate network\" showing the strength of the relationships amongst as many technology corporations as we can muster.\n",
    "\n",
    "The naive way of doing this would be to start with a simple model (say, `ConceptModel(['IBM'])`), `expand()` the graph, and then scrape the categorization of the associated Wikipedia pages (always remember that every concept is the name of a Wikipedia article!) in order to pare away all of the articles that were brought up where were not those belonging to companies. Let's time the naive way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 6,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "ibm = ConceptModel(['IBM'])\n",
    "ibm.explode(level=0)\n",
    "len(ibm.concepts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 10.709612846374512 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Digital Equipment Corporation', 0.89564085),\n",
       " ('Advanced Micro Devices', 0.79349726),\n",
       " ('Sun Microsystems', 0.780642),\n",
       " ('Oracle Corporation', 0.7744718),\n",
       " ('Intel', 0.6541496),\n",
       " ('Hewlett-Packard', 0.6270959)]"
      ]
     },
     "execution_count": 7,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "def scraper_timer(func):\n",
    "    def wrapper(model, starting_point):\n",
    "        start_time = time.time()\n",
    "        ret = func(model, starting_point)\n",
    "        print(\"Runtime: \" + str(time.time() - start_time) + \" seconds.\")\n",
    "        return ret\n",
    "    return wrapper\n",
    "\n",
    "def categories_snapshot(concept):\n",
    "    dat = requests.get('https://en.wikipedia.org/wiki/' + concept).text\n",
    "    return dat[dat.find(\"<div id='catlinks' class='catlinks'>\"):]\n",
    "\n",
    "def select(t, name):\n",
    "    if t[1] == name:\n",
    "        return t[2]\n",
    "    else:\n",
    "        return t[1]\n",
    "\n",
    "@scraper_timer\n",
    "def get_companies_with_scraping(model, starting_point):\n",
    "    top = [(select(edge, 'IBM'), edge[0]) for edge in model.edges()]\n",
    "    top_companies = [concept for concept in top if 'companies' in categories_snapshot(concept[0])]\n",
    "    return top_companies\n",
    "\n",
    "get_companies_with_scraping(ibm, 'IBM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly to slow to be of any practical use!\n",
    "\n",
    "Though web scrapers working in the main are somewhat faster at generating results than the Concept Insight API but definitely not fast enough to not get bogged down when you give it the enormous volume of pages to process that this operation requires. Plus rate unlimited scraping is also highly discouraged by Wikipedia itself, and running large-volume queries for long periods of time is liable to get you in trouble with the webmasters.\n",
    "\n",
    "So let's adopt our paradigm. Wikipedia [has an API](https://www.mediawiki.org/wiki/API:Main_page). It's admittedly a bit crufty but it's very powerful way of retrieving only the information that you need and retrieving it in fast batches. We use the [mwapi](https://pypi.python.org/pypi/mwapi/0.4.0) library to avoid writing the access code: this is a low-level library that is good for writing fast queries (written by two active Wikimedia Foundation developers for exactly that purpose). You can read the documentation [here](http://pythonhosted.org/mwapi/). You can try out queries and get a sense of how the API works in the [API sandbox](https://en.wikipedia.org/wiki/Special:ApiSandbox)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.1670088768005371 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sun Microsystems',\n",
       " 'Hewlett-Packard',\n",
       " 'IBM',\n",
       " 'Advanced Micro Devices',\n",
       " 'Intel',\n",
       " 'Digital Equipment Corporation',\n",
       " 'Oracle Corporation']"
      ]
     },
     "execution_count": 9,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "session = mwapi.Session('https://en.wikipedia.org', user_agent='watsongraph notebook')\n",
    "\n",
    "def api_timer(func):\n",
    "    def wrapper(model):\n",
    "        start_time = time.time()\n",
    "        ret = func(model)\n",
    "        print(\"Runtime: \" + str(time.time() - start_time) + \" seconds.\")\n",
    "        return ret\n",
    "    return wrapper\n",
    "\n",
    "# @api_timer\n",
    "def get_companies_with_api(model):\n",
    "    companies = []\n",
    "    cont = \"\"\n",
    "    while True:\n",
    "        raw = session.get(action='query',\n",
    "                          prop='categories',\n",
    "                          clshow='!hidden',\n",
    "                          cllimit=500,\n",
    "                          titles='|'.join(model.concepts()))\n",
    "                          # clcontinue=cont if cont else '???')\n",
    "        query = raw['query']['pages']\n",
    "        for p_k in query.keys():\n",
    "            if query[p_k]['title'] not in companies:\n",
    "                for cat in query[p_k]['categories']:\n",
    "                    if 'companies' in cat['title'] or 'Companies' in cat['title']:\n",
    "                        # print('Spotted: ' + cat['title'])\n",
    "                        companies.append(query[p_k]['title'])\n",
    "                        break\n",
    "        if 'batchcomplete' in raw.keys():\n",
    "            break\n",
    "        else:\n",
    "            cont = raw['clcontinue']\n",
    "    return companies\n",
    "\n",
    "start_time = time.time()\n",
    "ret = get_companies_with_api(ibm)\n",
    "print(\"Runtime: \" + str(time.time() - start_time) + \" seconds.\")\n",
    "ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Much* faster! But notice the difference between this output, which is just a `list` of things, and what we had previously: edges in a `ConceptModel` object. But following along with the logic that I mentioned earlier, it is much, much faster to create this list and then populate its edges - using a new method we will introduce for this purpose, `add_edges()` - then it is to work with them from the start.\n",
    "\n",
    "`add_edges()` extends the Concent Insights `getGraphRelationScore` API method and maps edges correlating a single `source_concept` (the first required argument) and an arbitrary `list_of_target_concepts` (the second required argument). If you recall the examples on entropy at the beginning of this notebook you will remember that the `wikipedia/en-20120601` cognitive graph we are using has very low entropy: for two concepts to be associated with one another at all they must be very tightly associated. This can cause surprising results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'concept': '/graphs/wikipedia/en-20120601/concepts/Interpretive_dance',\n",
       "  'score': 0.5},\n",
       " {'concept': '/graphs/wikipedia/en-20120601/concepts/Apple', 'score': 0.5},\n",
       " {'concept': '/graphs/wikipedia/en-20120601/concepts/Apple_Inc.',\n",
       "  'score': 0.5},\n",
       " {'concept': '/graphs/wikipedia/en-20120601/concepts/Microsoft', 'score': 0.5},\n",
       " {'concept': '/graphs/wikipedia/en-20120601/concepts/Java_(programming_language)',\n",
       "  'score': 0.60449404},\n",
       " {'concept': '/graphs/wikipedia/en-20120601/concepts/Intel',\n",
       "  'score': 0.6541496},\n",
       " {'concept': '/graphs/wikipedia/en-20120601/concepts/Cloud_computing',\n",
       "  'score': 0.6814177},\n",
       " {'concept': '/graphs/wikipedia/en-20120601/concepts/Watson_(computer)',\n",
       "  'score': 0.899236}]"
      ]
     },
     "execution_count": 10,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "from watsongraph.event_insight_lib import get_relation_scores\n",
    "get_relation_scores('IBM', ['Interpretive dance',\n",
    "                            'Apple',\n",
    "                            'Apple Inc.',\n",
    "                            'Microsoft',\n",
    "                            'Java (programming language)',\n",
    "                            'Intel',\n",
    "                            'Cloud computing',\n",
    "                            'Watson (computer)'\n",
    "                           ])['scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We as humans know that IBM has a heck of a lot more to do with Apple Inc. and with Microsoft then it does with apples and interpretive dance, but alas, because of the tightness of its cognitive graph, Watson doesn't. Watson always returns a value of `0.5` for edges that it doesn't know enough about to be sure of a correlation or that it doesn't think are particularly correlated. To account for this systematic limitation `add_edges()` offers an additional optional parameter, `prune`, which is set to `False` by default; if we add a `prune=True` argument the method will throw out all of these questionably useful edges and only keep those that return a `score` higher than 0.5.\n",
    "\n",
    "With all of this in mind let's work through a complete construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 2.3711349964141846 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.89564085, 'Digital Equipment Corporation', 'IBM'),\n",
       " (0.79349726, 'Advanced Micro Devices', 'IBM'),\n",
       " (0.780642, 'Sun Microsystems', 'IBM'),\n",
       " (0.7744718, 'IBM', 'Oracle Corporation'),\n",
       " (0.6541496, 'Intel', 'IBM'),\n",
       " (0.6270959, 'Hewlett-Packard', 'IBM')]"
      ]
     },
     "execution_count": 11,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "companies = get_companies_with_api(ibm)\n",
    "companies = ConceptModel(companies)\n",
    "companies.concepts()\n",
    "companies.add_edges('IBM', companies.concepts(), prune=True)\n",
    "print(\"Runtime: \" + str(time.time() - start_time) + \" seconds.\")\n",
    "companies.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already much faster! And this difference in execution time rapidly becomes more pronounced as you get to more intensive queries.\n",
    "\n",
    "The moral of the story is, to reiterate, that we should avoid using unstructured IBM Watson output as much as possible when defining our graph, and rely on it only in the end step, when we are linking together the nodes that we have hopefully populated from a different source. That source need not be the Wikipedia API: heavens knows there are a lot of ways of getting lists of companies out there on the Internet. The Wikipedia API is just a very durable multipurpose tool for getting there.\n",
    "\n",
    "One final note: there are also `explode_edges([prune=True/False])` and `add_edge([source, target, [prune=True/False]])` methods available for your use. The former is like `explode()`, but for edges: it creates every possible edge that it can. The latter creates only a single edge, and is not really recommended, as you should always try to handle this job in batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterization\n",
    "\n",
    "Daily page views are a bit of feature sugar that comes prebuilt in the `watsongraph` library. This data is based on a 30-day average, and is generated by a call against the (just recently introduced!) [Wikipedia Pageview API](https://wikimedia.org/api/rest_v1/?doc).\n",
    "\n",
    "These are a significant additional overhead on execution time and so are not instantiated for you, but you can do it yourself at any time using the `set_view_counts()` method. `concepts_by_view_count()` is useful for visualizing the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4427, 'IBM'),\n",
       " (3734, 'Hewlett-Packard'),\n",
       " (2972, 'Oracle Corporation'),\n",
       " (2876, 'Intel'),\n",
       " (1284, 'Advanced Micro Devices'),\n",
       " (1045, 'Sun Microsystems'),\n",
       " (617, 'Digital Equipment Corporation')]"
      ]
     },
     "execution_count": 12,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "companies.set_view_counts()\n",
    "companies.concepts_by_view_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `view_count` parameter is actually just one of any number of arbitrary properties that a `ConceptModel` can store for its nodes; `relevance` is the other one that's used extensively in-code, in the `User` and `Item` classes.\n",
    "\n",
    "This means that you can always extend the `ConceptModel` implicitly by defining and storing your own properties. There are two methods that allow you to do so. The first is the per-concept `set_property()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies.set_property('IBM', 'length', len('IBM'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A smarter way is to use `map_property()`, which accepts a function that should take a concept string as an argument. This method maps the property for *every* node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies.map_property('length', lambda concept: len(concept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `concepts_by_property()` to list out your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(29, 'Digital Equipment Corporation'),\n",
       " (22, 'Advanced Micro Devices'),\n",
       " (18, 'Oracle Corporation'),\n",
       " (16, 'Sun Microsystems'),\n",
       " (15, 'Hewlett-Packard'),\n",
       " (5, 'Intel'),\n",
       " (3, 'IBM')]"
      ]
     },
     "execution_count": 15,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "companies.concepts_by_property('length')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}